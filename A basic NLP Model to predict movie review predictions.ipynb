{
 "cells":[
  {
   "cell_type":"code",
   "source":[
    "import spacy\n",
    "#Downloading and importing the baseline model required\n",
    "import subprocess\n",
    "#%%\n",
    "print(subprocess.getoutput(\"python -m spacy download en_core_web_lg\"))\n",
    "nlp = spacy.load('en_core_web_lg')"
   ],
   "execution_count":1,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "Collecting en-core-web-lg==3.2.0\n",
      "  Downloading https:\/\/github.com\/explosion\/spacy-models\/releases\/download\/en_core_web_lg-3.2.0\/en_core_web_lg-3.2.0-py3-none-any.whl (777.4 MB)\n",
      "Requirement already satisfied: spacy<3.3.0,>=3.2.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from en-core-web-lg==3.2.0) (3.2.2)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (1.0.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (4.62.3)\n",
      "Requirement already satisfied: pathy>=0.3.5 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (0.6.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (3.0.8)\n",
      "Requirement already satisfied: jinja2 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (3.0.3)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (0.4.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (3.0.6)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (1.0.6)\n",
      "Requirement already satisfied: numpy>=1.15.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (1.21.5)\n",
      "Requirement already satisfied: packaging>=20.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (21.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: setuptools in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (56.0.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (3.3.0)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (8.0.13)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (1.8.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (2.26.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (2.4.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (0.7.6)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (0.9.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (3.0.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (4.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (1.26.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (2.0.12)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in \/opt\/python\/envs\/default\/lib\/python3.8\/site-packages (from jinja2->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (2.1.0)\n",
      "Installing collected packages: en-core-web-lg\n",
      "Successfully installed en-core-web-lg-3.2.0\n",
      "WARNING: You are using pip version 21.3.1; however, version 22.0.3 is available.\n",
      "You should consider upgrading via the '\/opt\/python\/envs\/default\/bin\/python -m pip install --upgrade pip' command.\n",
      "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_lg')\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# import important modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# sklearn modules\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB # classifier \n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    plot_confusion_matrix,\n",
    ")\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "# text preprocessing modules\n",
    "from string import punctuation \n",
    "\n",
    "# text preprocessing modules\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "import re #regular expression\n",
    "\n",
    "# Download dependency\n",
    "for dependency in (\n",
    "    \"brown\",\n",
    "    \"names\",\n",
    "    \"wordnet\",\n",
    "    \"averaged_perceptron_tagger\",\n",
    "    \"universal_tagset\",\n",
    "    \"stopwords\",\n",
    "    \"omw-1.4\"\n",
    "):\n",
    "    nltk.download(dependency)\n",
    "    \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# seeding\n",
    "np.random.seed(123)"
   ],
   "execution_count":2,
   "outputs":[
    {
     "name":"stderr",
     "text":[
      "[nltk_data] Downloading package brown to \/home\/datalore\/nltk_data...\n",
      "[nltk_data]   Unzipping corpora\/brown.zip.\n",
      "[nltk_data] Downloading package names to \/home\/datalore\/nltk_data...\n",
      "[nltk_data]   Unzipping corpora\/names.zip.\n",
      "[nltk_data] Downloading package wordnet to \/home\/datalore\/nltk_data...\n",
      "[nltk_data]   Unzipping corpora\/wordnet.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     \/home\/datalore\/nltk_data...\n",
      "[nltk_data]   Unzipping taggers\/averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     \/home\/datalore\/nltk_data...\n",
      "[nltk_data]   Unzipping taggers\/universal_tagset.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     \/home\/datalore\/nltk_data...\n",
      "[nltk_data]   Unzipping corpora\/stopwords.zip.\n",
      "[nltk_data] Downloading package omw-1.4 to \/home\/datalore\/nltk_data...\n",
      "[nltk_data]   Unzipping corpora\/omw-1.4.zip.\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# load data\n",
    "data = pd.read_csv(\"\/data\/notebook_files\/labeledTrainData.tsv\", sep='\\t')"
   ],
   "execution_count":3,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# show top five rows of data\n",
    "data.head() "
   ],
   "execution_count":4,
   "outputs":[
    {
     "data":{
      "text\/html":[
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "<\/style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th><\/th>\n",
       "      <th>id<\/th>\n",
       "      <th>sentiment<\/th>\n",
       "      <th>review<\/th>\n",
       "    <\/tr>\n",
       "  <\/thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0<\/th>\n",
       "      <td>5814_8<\/td>\n",
       "      <td>1<\/td>\n",
       "      <td>With all this stuff going down at the moment w...<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>1<\/th>\n",
       "      <td>2381_9<\/td>\n",
       "      <td>1<\/td>\n",
       "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>2<\/th>\n",
       "      <td>7759_3<\/td>\n",
       "      <td>0<\/td>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>3<\/th>\n",
       "      <td>3630_4<\/td>\n",
       "      <td>0<\/td>\n",
       "      <td>It must be assumed that those who praised this...<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <th>4<\/th>\n",
       "      <td>9495_8<\/td>\n",
       "      <td>1<\/td>\n",
       "      <td>Superbly trashy and wondrously unpretentious 8...<\/td>\n",
       "    <\/tr>\n",
       "  <\/tbody>\n",
       "<\/table>\n",
       "<\/div>"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# check the shape of the data\n",
    "data.shape"
   ],
   "execution_count":5,
   "outputs":[
    {
     "data":{
      "text\/plain":[
       "(25000, 3)"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# evalute news sentiment distribution\n",
    "data['sentiment'].value_counts()"
   ],
   "execution_count":6,
   "outputs":[
    {
     "data":{
      "text\/html":[
       
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "stop_words =  stopwords.words('english')\n",
    "\n",
    "def text_cleaning(text, remove_stop_words=True, lemmatize_words=True):\n",
    "    # Clean the text, with the option to remove stop_words and to lemmatize word\n",
    "    \n",
    "    # Clean the text\n",
    "    text = re.sub(r\"[^A-Za-z0-9]\", \" \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text =  re.sub(r'http\\S+',' link ', text)\n",
    "    text = re.sub(r'\\b\\d+(?:\\.\\d+)?\\s+', '', text) # remove numbers\n",
    "    doc = nlp(text) \n",
    "    # Remove punctuation from text\n",
    "    text = [token.text for token in doc if token.is_alpha is False]\n",
    "    text = \" \".join(text)\n",
    "    \n",
    "    # Optionally, remove stop words\n",
    "    if remove_stop_words:\n",
    "        text = [token.text for token in doc if token.is_stop is False]\n",
    "        text = \" \".join(text)\n",
    "    \n",
    "    # Optionally, shorten words to their stems\n",
    "    if lemmatize_words: \n",
    "        lemmatized_words = [token.lemma_ for token in doc]\n",
    "        text = \" \".join(lemmatized_words)\n",
    "    \n",
    "    # Return a list of words\n",
    "    return(text)"
   ],
   "execution_count":17,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "#clean the review\n",
    "data[\"cleaned_review\"] = data[\"review\"].apply(text_cleaning)"
   ],
   "execution_count":8,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "#split features and target from  data \n",
    "X = data[\"cleaned_review\"]\n",
    "y = data.sentiment.values"
   ],
   "execution_count":9,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.15,\n",
    "    random_state=42,\n",
    "    shuffle=True,\n",
    "    stratify=y,\n",
    ")"
   ],
   "execution_count":10,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# Create a classifier in pipeline\n",
    "sentiment_classifier = Pipeline(steps=[\n",
    "                                 ('pre_processing',TfidfVectorizer(lowercase=False)),\n",
    "                                 ('naive_bayes',MultinomialNB())\n",
    "                                 ])"
   ],
   "execution_count":11,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# train the sentiment classifier \n",
    "\n",
    "sentiment_classifier.fit(X_train,y_train)"
   ],
   "execution_count":12,
   "outputs":[
    {
     "data":{
      "text\/plain":[
       "Pipeline(steps=[('pre_processing', TfidfVectorizer(lowercase=False)),\n",
       "                ('naive_bayes', MultinomialNB())])"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# test model performance on valid data \n",
    "y_preds = sentiment_classifier.predict(X_valid)"
   ],
   "execution_count":13,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "accuracy_score(y_valid,y_preds)"
   ],
   "execution_count":14,
   "outputs":[
    {
     "data":{
      "text\/plain":[
       "0.8626666666666667"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "#save model \n",
    "import joblib \n",
    "\n",
    "joblib.dump(sentiment_classifier, '\/data\/notebook_files\/sentiment_model_pipeline.pkl')"
   ],
   "execution_count":15,
   "outputs":[
    {
     "data":{
      "text\/plain":[
       "['\/data\/notebook_files\/sentiment_model_pipeline.pkl']"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    
   ],
   "execution_count":0,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "type":"CODE",
     "hide_input_from_viewers":false,
     "hide_output_from_viewers":false
    }
   }
  }
 ],
 "metadata":{
  "datalore":{
   "version":1,
   "computation_mode":"JUPYTER",
   "package_manager":"pip",
   "base_environment":"default",
   "packages":[
    {
     "name":"nltk",
     "source":"PIP"
    }
   ]
  }
 },
 "nbformat":4,
 "nbformat_minor":4
}